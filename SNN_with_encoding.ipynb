{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caa51485-8420-47d7-b06c-9a8d2ca1e75b",
   "metadata": {},
   "source": [
    "So this is a working convolutional SNN with the Architecture proposed by that one paper I suggested.\n",
    "This is neither optimized code nor is it compatible with our data yet but I thought it is a reasonable starting place.\n",
    "\n",
    "So this Network receives the raw data as inputs not spikes. It seems easiest to just put in the spectogram data (what we called voltage) into the LIF neurons instead of using the poisson encoding first. (poisson encoding was at least useful for us to see if we can generate sensible spikes from the data).  \n",
    "\n",
    "Right now there is a convolution on the input data itself, I would start out by trying to avoid and only convolve in the spike domain, but we'll see. I'm also unsere whether we should give the input timestep by timestep or not. With the setup right now, it expects it all at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa60ccfd-ae43-474d-b21d-0caf14a7354d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from spikingjelly.activation_based import neuron, functional, surrogate, layer\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b76fa63a-098d-46b6-af13-becd05beb688",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torchaudio\n",
    "\n",
    "train_set = torchaudio.datasets.SPEECHCOMMANDS(root='./data', download=True, subset='training')\n",
    "test_set = torchaudio.datasets.SPEECHCOMMANDS(root='./data', download=True, subset='testing')\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\"\"\"\n",
    "def collate_fn(batch):\n",
    "    # batch is a list of tuples (waveform, label)\n",
    "    waveforms,_, labels,_,_ = zip(*batch)\n",
    "    # Pad sequences dynamically to match the length of the longest in the batch\n",
    "    waveforms_padded = pad_sequence(waveforms, batch_first=True, padding_value=0)\n",
    "    labels = torch.tensor(labels)\n",
    "    return waveforms_padded, labels\n",
    "\"\"\"\n",
    "max_length = 16000  # or your desired length\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assume `labels` contains the string labels from your dataset\n",
    "label_encoder = LabelEncoder()\n",
    "#encoded_labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    max_length = 16000\n",
    "    waveforms, labels = zip(*[(item[0].squeeze()[:max_length], item[2]) for item in batch])\n",
    "    \n",
    "    # Ensure each waveform is 1D before padding\n",
    "    waveforms = [waveform if waveform.ndim == 1 else waveform.mean(dim=0) for waveform in waveforms]\n",
    "    \n",
    "    #print(\"Shapes before padding:\", [w.shape for w in waveforms])  # Add this line\n",
    "    \n",
    "    waveforms_padded = pad_sequence(waveforms, batch_first=True, padding_value=0)\n",
    "\n",
    "    labels = label_encoder.fit_transform(labels)  # Encode the labels as integers\n",
    "    \n",
    "    labels = torch.tensor(labels)\n",
    "    #print('done')\n",
    "    return waveforms_padded, labels\n",
    "\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=64, shuffle=True, collate_fn=collate_fn, drop_last=True)\n",
    "test_loader = DataLoader(test_set, batch_size=64, shuffle=False, collate_fn=collate_fn, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8894dff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal.windows import exponential, gaussian\n",
    "from scipy.signal import square, ShortTimeFFT\n",
    "\n",
    "\n",
    "sample_rate=16000\n",
    "g_std = 10      # standard deviation for Gaussian window in samples\n",
    "win_size = 40   # window size in samples\n",
    "win_gauss = gaussian(win_size, std=g_std, sym=True)  # symmetric Gaussian wind.\n",
    "SFT = ShortTimeFFT(win_gauss, hop=2, fs=sample_rate, mfft=2000, scale_to='psd')\n",
    "batch_size = 64\n",
    "num_samples = 16000\n",
    "\n",
    "duration = num_samples / sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2421918",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import stft\n",
    "import librosa\n",
    "\n",
    "def mel_spectrogram(audio, sample_rate, n_mels=128, f_min=0, f_max=None):\n",
    "  if f_max is None:\n",
    "    f_max = sample_rate / 2\n",
    "  _, _, spectrogram = stft(audio, nperseg=512, noverlap=256, fs=sample_rate)\n",
    "  #print(\"spectrogram: \", spectrogram.shape)\n",
    "  # mel_spectrogram = mel(spectrogram, sr=sample_rate, n_mels=n_mels, fmin=f_min, fmax=f_max)\n",
    "  mel_spectrogram = mel(spectrogram, sr=sample_rate, n_mels=n_mels, fmin=f_min, fmax=f_max)\n",
    "  return mel_spectrogram\n",
    "\n",
    "def mel(spectrogram, sr=44100, n_mels=128, fmin=0, fmax=None):\n",
    "  return librosa.feature.melspectrogram(S=spectrogram, sr=sr, n_mels=n_mels, fmin=fmin, fmax=fmax)\n",
    "\n",
    "class RBFNetwork:\n",
    "  def __init__(self, input_dim, num_centers, sigma):\n",
    "    self.centers = np.random.rand(num_centers, input_dim)  # Initialize centers randomly\n",
    "    #print(\"centers: \", self.centers.shape)\n",
    "    self.sigma = sigma\n",
    "\n",
    "  def rbf(self, x):\n",
    "    #print(\"x: \", x.shape)\n",
    "    #print(\"centers: \", self.centers.shape)\n",
    "    # return np.exp(-np.linalg.norm(x - self.centers, axis=1) ** 2 / (2 * self.sigma ** 2))\n",
    "    def compute_distances(xi):\n",
    "            # xi - self.centers creates a new array where each center is subtracted from xi\n",
    "            # np.linalg.norm(..., axis=1) computes the norm along the axis of the centers\n",
    "            return np.linalg.norm(xi - self.centers, axis=1)\n",
    "    norms = np.apply_along_axis(compute_distances, 1, x)\n",
    "    return np.exp(- norms ** 2 / (2 * self.sigma ** 2))\n",
    "    \n",
    "  def predict(self, X):\n",
    "    #print(\"## predict ##\")\n",
    "    #print(\"X: \", X.shape)\n",
    "    y = self.rbf(X)\n",
    "    #print(\"y: \", y.shape)\n",
    "    # normalize to 0 - 1 along the batch dimension\n",
    "    y = (y - np.min(y, axis=0)) / (np.max(y, axis=0) - np.min(y, axis=0))\n",
    "    return y\n",
    "\n",
    "def rbf_encode_audio(audio, sample_rate, SFT, n_mels=128, num_rbf=256, sigma=1.0):\n",
    "  mel_spec = mel_spectrogram(audio, sample_rate, n_mels)\n",
    "  mel_spec = np.abs(mel_spec)\n",
    "  # mel_spec = SFT.spectrogram(audio)\n",
    "  #print(\"shape mel_spec: \", mel_spec.shape)\n",
    "  rbf_network = RBFNetwork(mel_spec.shape[0], num_rbf//10, sigma)\n",
    "  rbf_activations = rbf_network.predict(mel_spec.T)  # transpose to get the batch dimension first\n",
    "  return rbf_activations, mel_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f996e6ac-1879-436b-80a7-e89102d27df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0 torch.Size([64, 25, 1])\n",
      "x1 torch.Size([64, 16, 1])\n",
      "x2 torch.Size([64, 16, 1])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "max_pool1d() Invalid computed output size: 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 101\u001b[0m\n\u001b[0;32m     98\u001b[0m num_time_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# Assuming train_loader is correctly defined and provides batches of (inputs, labels)\u001b[39;00m\n\u001b[1;32m--> 101\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_time_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m35\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43msr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msr\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 74\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, dataloader, optimizer, loss_fn, num_time_steps, num_classes, batch_size, sr)\u001b[0m\n\u001b[0;32m     72\u001b[0m spike_input \u001b[38;5;241m=\u001b[39m spikes[:, :, t] \u001b[38;5;66;03m# Shape: [batch_size, 1, num_time_steps]\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m#print(spike_input.shape, spike_input.unsqueeze(1).shape)\u001b[39;00m\n\u001b[1;32m---> 74\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspike_input\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m#output = model(spike_input)\u001b[39;00m\n\u001b[0;32m     76\u001b[0m outputs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m output  \u001b[38;5;66;03m# Aggregate outputs over time\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[5], line 30\u001b[0m, in \u001b[0;36mSpikingCNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     28\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlif1(x)  \n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx2\u001b[39m\u001b[38;5;124m'\u001b[39m, x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 30\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpool1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m            \n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx3\u001b[39m\u001b[38;5;124m'\u001b[39m, x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     32\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x) \n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\pooling.py:91\u001b[0m, in \u001b[0;36mMaxPool1d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor):\n\u001b[1;32m---> 91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_pool1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mceil_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mreturn_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_indices\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\_jit_internal.py:497\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    496\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_false(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\functional.py:710\u001b[0m, in \u001b[0;36m_max_pool1d\u001b[1;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[0;32m    708\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stride \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    709\u001b[0m     stride \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mannotate(List[\u001b[38;5;28mint\u001b[39m], [])\n\u001b[1;32m--> 710\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_pool1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: max_pool1d() Invalid computed output size: 0"
     ]
    }
   ],
   "source": [
    "# old model,ignore and use the next one\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import spikingjelly as sj\n",
    "#from spikingjelly import surrogate, neuron\n",
    "\n",
    "class SpikingCNN(nn.Module):\n",
    "    def __init__(self, num_classes, spike_grad=surrogate.ATan(), threshold=1.0, num_time_steps=16000):\n",
    "        super(SpikingCNN, self).__init__()\n",
    "        self.num_time_steps = num_time_steps\n",
    "        self.conv1 = nn.Conv1d(25, 16, kernel_size=3, stride=1, padding=1)  # [batch_size, 16, num_time_steps]\n",
    "        self.lif1 = neuron.LIFNode(surrogate_function=spike_grad, v_threshold=threshold)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2, stride=2)  # [batch_size, 16, num_time_steps // 2]\n",
    "        self.lif2 = neuron.LIFNode(surrogate_function=spike_grad, v_threshold=threshold)\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=2, stride=2)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.lif3 = neuron.LIFNode(surrogate_function=spike_grad, v_threshold=threshold)\n",
    "        self.fc1 = nn.Linear(256, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x should be [batch_size, num_features, num_time_steps]\n",
    "        print('x0', x.shape)\n",
    "        x = self.conv1(x)\n",
    "        print('x1', x.shape)\n",
    "        x = self.lif1(x)  \n",
    "        print('x2', x.shape)\n",
    "        x = self.pool1(x)            \n",
    "        print('x3', x.shape)\n",
    "        x = self.conv2(x) \n",
    "        print('x4', x.shape) #\n",
    "        x = self.lif2(x)\n",
    "        print('x5', x.shape)\n",
    "        x = self.pool2(x) #\n",
    "        print('x6', x.shape)\n",
    "        x = x.view(x.size(0), -1)   \n",
    "        #print(x.shape)\n",
    "        x = self.lif3(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        print(x.shape)\n",
    "        return x\n",
    "\n",
    "def encode_to_spikes(data, sr, tau_m=20.0, R=1.0, V_th=1.0, V_reset=0.0):\n",
    "    batch_size = data.size(0)\n",
    "    num_features = 25\n",
    "    num_time_steps = 64\n",
    "    spikes = torch.zeros(batch_size, num_features, num_time_steps, device=data.device)\n",
    "    for i in range(batch_size):\n",
    "        rbf_activations, mel_spec = rbf_encode_audio(data[i], sr, SFT=SFT)\n",
    "        spike_prob_scale = 1.7\n",
    "        rbf_activations_traversed = rbf_activations.T\n",
    "        spik_probs = rbf_activations_traversed / np.max(rbf_activations_traversed, axis=1, keepdims=True) * spike_prob_scale \n",
    "        spike_trains = np.random.poisson(spik_probs[...] * duration, size=rbf_activations_traversed.shape)\n",
    "        spike_trains = np.clip(spike_trains, 0, 1)\n",
    "        spikes[i] = torch.from_numpy(spike_trains)\n",
    "        \n",
    "    return spikes\n",
    "\n",
    "def train(model, dataloader, optimizer, loss_fn, num_time_steps, num_classes, batch_size,sr):\n",
    "    model.train()\n",
    "    count = 0\n",
    "    for batch in dataloader:\n",
    "        inputs, labels = batch\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        spikes = encode_to_spikes(inputs, sr)\n",
    "        outputs = torch.zeros(inputs.size(0), num_classes, device=inputs.device)  # Accumulate outputs\n",
    "        \n",
    "        for t in range(num_time_steps):\n",
    "            spike_input = spikes[:, :, t] # Shape: [batch_size, 1, num_time_steps]\n",
    "            #print(spike_input.shape, spike_input.unsqueeze(1).shape)\n",
    "            output = model(spike_input.unsqueeze(2))\n",
    "            #output = model(spike_input)\n",
    "            outputs += output  # Aggregate outputs over time\n",
    "\n",
    "        # Compute loss and backpropagate\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()  # Use surrogate gradients\n",
    "        optimizer.step()\n",
    "\n",
    "        # Optionally, print or log training progress\n",
    "        \n",
    "        if count % 100 == 0:\n",
    "            print(count, f\"Loss: {loss.item()}\")\n",
    "        functional.reset_net(model)\n",
    "        count += 1\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "model = SpikingCNN(num_classes=35)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "sr = 16000  # Number of time steps to simulate\n",
    "batch_size = 64\n",
    "num_time_steps=64\n",
    "\n",
    "# Assuming train_loader is correctly defined and provides batches of (inputs, labels)\n",
    "train(model, train_loader, optimizer, loss_fn, num_time_steps, num_classes=35, batch_size=batch_size,sr=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ae42e18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    \\n# real spectograms\\ndef encode_to_spikes(data, sr, tau_m=20.0, R=1.0, V_th=1.0, V_reset=0.0):\\n    batch_size = data.size(0)\\n    num_features = 128\\n    num_time_steps = 64\\n    specs = torch.zeros(batch_size, num_features, num_time_steps, device=data.device)\\n    for i in range(batch_size):\\n        #rbf_activations, mel_spec = rbf_encode_audio(data[i], sr, SFT=SFT)\\n        spec = mel_spectrogram(data[i],sr)\\n        specs[i] = torch.from_numpy(spec)\\n        \\n    return rbfs\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import snntorch as snn\n",
    "from snntorch import surrogate\n",
    "from snntorch import utils as sutils\n",
    "from snntorch.functional import quant\n",
    "\n",
    "class customSNet(nn.Module):\n",
    "    def __init__(self, num_steps, beta, threshold=1.0, spike_grad=snn.surrogate.fast_sigmoid(slope=25), num_class=10):\n",
    "        super().__init__()\n",
    "        self.num_steps = num_steps\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.lif1 = snn.Leaky(beta=beta, spike_grad=spike_grad, threshold=threshold)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        self.lif2 = snn.Leaky(beta=beta, spike_grad=spike_grad, threshold=threshold)\n",
    "        self.fc1 = nn.Linear(896, 128)  # use 6720 for real spektogram, 896 for spikes or rbf activity\n",
    "        #self.fc1 = nn.Linear(6720, 128) # use 6720 for real spektogram, 896 for spikes or rbf activity\n",
    "        self.lif3 = snn.Leaky(beta=beta, spike_grad=spike_grad, threshold=threshold)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.lif4 = snn.Leaky(beta=beta, spike_grad=spike_grad, threshold=threshold)\n",
    "        self.fc3 = nn.Linear(64, num_class)\n",
    "        self.lif5 = snn.Leaky(beta=beta, spike_grad=spike_grad, threshold=threshold)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden states and outputs at t=0\n",
    "        batch_size_curr = x.shape[0]\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky() \n",
    "        mem3 = self.lif3.init_leaky()\n",
    "        mem4 = self.lif4.init_leaky()\n",
    "        mem5 = self.lif5.init_leaky()\n",
    "\n",
    "        # Record the final layer\n",
    "        spk5_rec = []\n",
    "        mem5_rec = []\n",
    "\n",
    "        for step in range(self.num_steps):\n",
    "            #print('x0', x.shape)\n",
    "            cur1 = self.pool(self.conv1(x))\n",
    "            #cur1 = self.conv1(x)\n",
    "            #print('x1', x.shape)\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            #print('x2', spk1.shape, mem1.shape)\n",
    "            cur2 = self.pool(self.conv2(spk1))\n",
    "            #cur2 = self.conv2(spk1)\n",
    "            #print('x3', cur2.shape)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "            #print('x4', spk2.shape, mem2.shape)\n",
    "            cur3 = self.fc1(spk2.view(batch_size_curr, -1))\n",
    "            #print('x5', cur3.shape)\n",
    "            spk3, mem3 = self.lif3(cur3, mem3)\n",
    "            #print('x6', spk3.shape, mem3.shape)\n",
    "            cur4 = self.fc2(spk3)\n",
    "            #print('x7', cur4.shape)\n",
    "            spk4, mem4 = self.lif4(cur4, mem4)\n",
    "            #print('x8', spk4.shape, mem4.shape)\n",
    "            cur5 = self.fc3(spk4)\n",
    "            #print('x9', cur5.shape)\n",
    "            spk5, mem5 = self.lif5(cur5, mem5)\n",
    "            #print('x10', spk5.shape, mem5.shape)\n",
    "            \n",
    "            spk5_rec.append(spk5)\n",
    "            mem5_rec.append(mem5)\n",
    "\n",
    "        return torch.stack(spk5_rec), torch.stack(mem5_rec)\n",
    "    \n",
    "# poisson spikes from rbf activity\n",
    "def encode_to_spikes(data, sr, tau_m=20.0, R=1.0, V_th=1.0, V_reset=0.0):\n",
    "    batch_size = data.size(0)\n",
    "    num_features = 25\n",
    "    num_time_steps = 64\n",
    "    spikes = torch.zeros(batch_size, num_features, num_time_steps, device=data.device)\n",
    "    rbfs = []\n",
    "    for i in range(batch_size):\n",
    "        rbf_activations, mel_spec = rbf_encode_audio(data[i], sr, SFT=SFT)\n",
    "        rbfs.append(rbf_activations)\n",
    "        spike_prob_scale = 1.7\n",
    "        rbf_activations_traversed = rbf_activations.T\n",
    "        spik_probs = rbf_activations_traversed / np.max(rbf_activations_traversed, axis=1, keepdims=True) * spike_prob_scale \n",
    "        spike_trains = np.random.poisson(spik_probs[...] * duration, size=rbf_activations_traversed.shape)\n",
    "        spike_trains = np.clip(spike_trains, 0, 1)\n",
    "        spikes[i] = torch.from_numpy(spike_trains)\n",
    "        \n",
    "    return spikes\n",
    "\"\"\"\n",
    "# pseudo spectogram of rbf activity\n",
    "def encode_to_spikes(data, sr, tau_m=20.0, R=1.0, V_th=1.0, V_reset=0.0):\n",
    "    batch_size = data.size(0)\n",
    "    num_features = 25\n",
    "    num_time_steps = 64\n",
    "    rbfs = torch.zeros(batch_size, num_features, num_time_steps, device=data.device)\n",
    "    for i in range(batch_size):\n",
    "        rbf_activations, mel_spec = rbf_encode_audio(data[i], sr, SFT=SFT)\n",
    "        rbf_activations_traversed = rbf_activations.T\n",
    "        rbfs[i] = torch.from_numpy(rbf_activations_traversed)\n",
    "        \n",
    "    return rbfs\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"    \n",
    "# real spectograms\n",
    "def encode_to_spikes(data, sr, tau_m=20.0, R=1.0, V_th=1.0, V_reset=0.0):\n",
    "    batch_size = data.size(0)\n",
    "    num_features = 128\n",
    "    num_time_steps = 64\n",
    "    specs = torch.zeros(batch_size, num_features, num_time_steps, device=data.device)\n",
    "    for i in range(batch_size):\n",
    "        #rbf_activations, mel_spec = rbf_encode_audio(data[i], sr, SFT=SFT)\n",
    "        spec = mel_spectrogram(data[i],sr)\n",
    "        specs[i] = torch.from_numpy(spec)\n",
    "        \n",
    "    return rbfs\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe966834",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 43\u001b[0m\n\u001b[0;32m     40\u001b[0m     loss_val \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_fn(mem_rec[step], labels)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Gradient calculation + weight update\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m \u001b[43mloss_val\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Store loss history for future plotting\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    524\u001b[0m     )\n\u001b[1;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\autograd\\__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\autograd\\graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    745\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    746\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\autograd\\function.py:286\u001b[0m, in \u001b[0;36mBackwardCFunction.apply\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mBackwardCFunction\u001b[39;00m(_C\u001b[38;5;241m.\u001b[39m_FunctionBase, FunctionCtx, _HookMixin):\n\u001b[0;32m    282\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;124;03m    This class is used for internal autograd work. Do not use.\u001b[39;00m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 286\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m    287\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;124;03m        Apply method used when executing this Node during the backward\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;124;03m        \"\"\"\u001b[39;00m\n\u001b[0;32m    290\u001b[0m         \u001b[38;5;66;03m# _forward_cls is defined by derived class\u001b[39;00m\n\u001b[0;32m    291\u001b[0m         \u001b[38;5;66;03m# The user should define either backward or vjp but never both.\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "import os\n",
    "from snntorch import functional as SF\n",
    "\n",
    "\n",
    "num_classes = 35\n",
    "num_steps = 10\n",
    "model = customSNet(num_steps = num_steps, beta = 0.9, threshold=1.0, spike_grad=snn.surrogate.fast_sigmoid(slope=25), num_class=num_classes)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "sr = 16000  # Number of time steps to simulate\n",
    "batch_size = 64\n",
    "train_loss_hist = []\n",
    "train_accu_hist = []\n",
    "train_accu_hist_temp = []\n",
    "#model.train()\n",
    "\n",
    "n_epochs = 5\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    iterCount = 0\n",
    "    for batch in train_loader:\n",
    "        inputs, labels = batch\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        spikes = encode_to_spikes(inputs, sr)\n",
    "        #outputs = torch.zeros(inputs.size(0), num_classes, device=inputs.device)  \n",
    "        spike_input = spikes.unsqueeze(1)\n",
    "\n",
    "        model.train()\n",
    "        spk_rec, mem_rec = model(spike_input)\n",
    "\n",
    "        loss_val = torch.zeros((1), dtype=torch.float)\n",
    "        for step in range(num_steps):\n",
    "            loss_val += loss_fn(mem_rec[step], labels)\n",
    "\n",
    "        # Gradient calculation + weight update\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Store loss history for future plotting\n",
    "        avg_loss = loss_val.item()/len(train_loader)\n",
    "        train_loss_hist.append(loss_val.item())\n",
    "        acc = SF.accuracy_rate(spk_rec, labels) \n",
    "        acc2 = SF.accuracy_temporal(spk_rec, labels) \n",
    "        train_accu_hist.append(acc)\n",
    "        train_accu_hist_temp.append(acc2)\n",
    "        iterCount +=1\n",
    "    print(f' Epoch: {epoch} | Train Loss: {train_loss_hist[-1]:.3f} | Avg Loss: {avg_loss:.3f} | Accuracy: {train_accu_hist[-1]:.3f} | Accuracy: {train_accu_hist_temp[-1]:.3f} | Iteration: {iterCount}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
